= Build and Modernize Applications With Generative AI 
:toc: manual

== Preconditions

[source, bash]
.*Setup IAM for using Gemini in GCP Project*
----
PROJECT_ID=$(gcloud config get-value project)
REGION=us-west1
echo "PROJECT_ID=${PROJECT_ID}"
echo "REGION=${REGION}"

USER=$(gcloud config get-value account 2> /dev/null)
echo "USER=${USER}"

gcloud services enable cloudaicompanion.googleapis.com --project ${PROJECT_ID}

gcloud projects add-iam-policy-binding ${PROJECT_ID} --member user:${USER} --role=roles/cloudaicompanion.user
gcloud projects add-iam-policy-binding ${PROJECT_ID} --member user:${USER} --role=roles/serviceusage.serviceUsageViewer
----

[source, bash]
.*Build docker image and deploy to cloud run*
----
docker build --platform linux/amd64 -t gcr.io/$PROJECT_ID/cymbal-inventory-api .

docker push gcr.io/$PROJECT_ID/cymbal-inventory-api

gcloud run deploy inventory --image=gcr.io/$PROJECT_ID/cymbal-inventory-api --port=8000 --region=us-central1 --set-env-vars=PROJECT_ID=$PROJECT_ID --allow-unauthenticated
----

== Getting Started with the Vertex AI Gemini API with cURL

* *Gemini Pro model (gemini-pro)*: Designed to handle natural language tasks, multiturn text and code chat, and code generation.
* *Gemini Pro Vision model (gemini-pro-vision)*: Supports multimodal prompts. You can include text, images, and video in your prompt requests and get text or code responses.

[source, bash]
.*Prepare Variable*
----
PROJECT_ID = ""
LOCATION = ""
API_ENDPOINT = "$LOCATION-aiplatform.googleapis.com"
MODEL_ID = "gemini-1.5-pro"

gsutil cp "gs://cloud-samples-data/generative-ai/image/320px-Felis_catus-cat_on_snow.jpg" ./image.jpg
----

[source, bash]
.*1. Generate content*
----
curl -X POST \
  -H "Authorization: Bearer $(gcloud auth print-access-token)" \
  -H "Content-Type: application/json" \
  https://${API_ENDPOINT}/v1/projects/${PROJECT_ID}/locations/${LOCATION}/publishers/google/models/${MODEL_ID}:generateContent \
  -d '{
    "contents": {
      "role": "USER",
      "parts": { "text": "Why is the sky blue?" }
    }
  }'
----

[source, bash]
.*2. Streaming*
----
curl -X POST \
  -H "Authorization: Bearer $(gcloud auth print-access-token)" \
  -H "Content-Type: application/json" \
  https://${API_ENDPOINT}/v1/projects/${PROJECT_ID}/locations/${LOCATION}/publishers/google/models/${MODEL_ID}:streamGenerateContent \
  -d '{
    "contents": {
      "role": "USER",
      "parts": { "text": "Why is the sky blue?" }
    }
  }'
----

[source, bash]
.*3. Model parameters*
----
curl -X POST \
  -H "Authorization: Bearer $(gcloud auth print-access-token)" \
  -H "Content-Type: application/json" \
  https://${API_ENDPOINT}/v1/projects/${PROJECT_ID}/locations/${LOCATION}/publishers/google/models/${MODEL_ID}:generateContent \
  -d '{
    "contents": {
      "role": "USER",
      "parts": [
        {"text": "Describe this image"},
        {"file_data": {
          "mime_type": "image/png",
          "file_uri": "gs://cloud-samples-data/generative-ai/image/320px-Felis_catus-cat_on_snow.jpg"
        }}
      ]
    },
    "generation_config": {
      "temperature": 0.2,
      "top_p": 0.1,
      "top_k": 16,
      "max_output_tokens": 2048,
      "candidate_count": 1,
      "stop_sequences": []
    },
    "safety_settings": {
      "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
      "threshold": "BLOCK_LOW_AND_ABOVE"
    }
  }'
----

[source, bash]
.*4. Chat*
----
curl -X POST \
  -H "Authorization: Bearer $(gcloud auth print-access-token)" \
  -H "Content-Type: application/json" \
  https://${API_ENDPOINT}/v1/projects/${PROJECT_ID}/locations/${LOCATION}/publishers/google/models/${MODEL_ID}:generateContent \
  -d '{
    "contents": [
      {
        "role": "user",
        "parts": [
          { "text": "Hello" }
        ]
      },
      {
        "role": "model",
        "parts": [
          { "text": "Hello! I am glad you could both make it." }
        ]
      },
      {
        "role": "user",
        "parts": [
          { "text": "So what is the first order of business?" }
        ]
      }
    ]
  }'
----

[source, bash]
.*5. Function calling*
----
curl -X POST \
  -H "Authorization: Bearer $(gcloud auth print-access-token)" \
  -H "Content-Type: application/json" \
  https://${API_ENDPOINT}/v1beta1/projects/${PROJECT_ID}/locations/${LOCATION}/publishers/google/models/${MODEL_ID}:generateContent \
  -d '{
  "contents": {
    "role": "user",
    "parts": {
      "text": "Which theaters in Mountain View show Barbie movie?"
    }
  },
  "tools": [
    {
      "function_declarations": [
        {
          "name": "find_movies",
          "description": "find movie titles currently playing in theaters based on any description, genre, title words, etc.",
          "parameters": {
            "type": "object",
            "properties": {
              "location": {
                "type": "string",
                "description": "The city and state, e.g. San Francisco, CA or a zip code e.g. 95616"
              },
              "description": {
                "type": "string",
                "description": "Any kind of description including category or genre, title words, attributes, etc."
              }
            },
            "required": [
              "description"
            ]
          }
        },
        {
          "name": "find_theaters",
          "description": "find theaters based on location and optionally movie title which are is currently playing in theaters",
          "parameters": {
            "type": "object",
            "properties": {
              "location": {
                "type": "string",
                "description": "The city and state, e.g. San Francisco, CA or a zip code e.g. 95616"
              },
              "movie": {
                "type": "string",
                "description": "Any movie title"
              }
            },
            "required": [
              "location"
            ]
          }
        },
        {
          "name": "get_showtimes",
          "description": "Find the start times for movies playing in a specific theater",
          "parameters": {
            "type": "object",
            "properties": {
              "location": {
                "type": "string",
                "description": "The city and state, e.g. San Francisco, CA or a zip code e.g. 95616"
              },
              "movie": {
                "type": "string",
                "description": "Any movie title"
              },
              "theater": {
                "type": "string",
                "description": "Name of theater"
              },
              "date": {
                "type": "string",
                "description": "Date for requested showtime"
              }
            },
            "required": [
              "location",
              "movie",
              "theater",
              "date"
            ]
          }
        }
      ]
    }
  ]
}'
----

NOTE: Function calling lets you create a description of a function in their code, then pass that description to a language model in a request. This sample is an example of passing in a description of a function that returns information about where a movie is playing. Several function declarations are included in the request, such as find_movies and find_theaters.

[source, bash]
.*6. Generate text from a local image*
----
data=$(base64 -w 0 image.jpg)

curl -X POST \
  -H "Authorization: Bearer $(gcloud auth print-access-token)" \
  -H "Content-Type: application/json" \
  https://${API_ENDPOINT}/v1/projects/${PROJECT_ID}/locations/${LOCATION}/publishers/google/models/${MODEL_ID}:generateContent \
  -d "{
      'contents': {
        'role': 'USER',
        'parts': [
          {
            'text': 'Is it a cat?'
          },
          {
            'inline_data': {
              'data': '${data}',
              'mime_type':'image/jpeg'
            }
          }
        ]
       }
     }"
----

[source, bash]
.*7. Generate text from an image on Google Cloud Storage*
----
MODEL_ID="gemini-1.5-pro"

curl -X POST \
  -H "Authorization: Bearer $(gcloud auth print-access-token)" \
  -H "Content-Type: application/json" \
  https://${API_ENDPOINT}/v1/projects/${PROJECT_ID}/locations/${LOCATION}/publishers/google/models/${MODEL_ID}:generateContent \
  -d '{
    "contents": {
      "role": "USER",
      "parts": [
        {
          "text": "Describe this image"
        },
        {
          "file_data": {
            "mime_type": "image/png",
            "file_uri": "gs://cloud-samples-data/generative-ai/image/320px-Felis_catus-cat_on_snow.jpg"
          }
        }
      ]
    },
    "generation_config": {
      "temperature": 0.2,
      "top_p": 0.1,
      "top_k": 16,
      "max_output_tokens": 2048,
      "candidate_count": 1,
      "stop_sequences": []
    },
    "safety_settings": {
      "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
      "threshold": "BLOCK_LOW_AND_ABOVE"
    }
  }'
----

[source, bash]
.*8. Generate text from a video file*
----
curl -X POST \
  -H "Authorization: Bearer $(gcloud auth print-access-token)" \
  -H "Content-Type: application/json" \
  https://${API_ENDPOINT}/v1/projects/${PROJECT_ID}/locations/${LOCATION}/publishers/google/models/${MODEL_ID}:generateContent \
  -d \
'{
    "contents": {
      "role": "USER",
      "parts": [
        {
          "text": "Answer the following questions using the video only. What is the profession of the main person? What are the main features of the phone highlighted?Which city was this recorded in?Provide the answer JSON."
        },
        {
          "file_data": {
            "mime_type": "video/mp4",
            "file_uri": "gs://github-repo/img/gemini/multimodality_usecases_overview/pixel8.mp4"
          }
        }
      ]
    }
  }'
----

== Function Calling 

Function calling lets developers create a description of a function in their code, then pass that description to a language model in a request. The response from the model includes the name of a function that matches the description and the arguments to call it with.

Imagine asking someone to write down important information without giving them a form or any guidelines on the structure. You might get a beautifully crafted paragraph, but extracting specific details like names, dates, or numbers would be tedious! Similarly, trying to get consistent structured data from a generative text model without function calling can be frustrating. You're stuck explicitly prompting for things like JSON output, often with inconsistent and frustrating results.

This is where Gemini Function Calling comes in. Instead of hoping for the best in a freeform text response from a generative model, you can define clear functions with specific parameters and data types. These function declarations act as structured guidelines, guiding the Gemini model to structure its output in a predictable and usable way. No more parsing text responses for important information!

Think of it like teaching Gemini to speak the language of your applications. Need to retrieve information from a database? Define a `search_db` function with parameters for search terms. Want to integrate with a weather API? Create a `get_weather` function that takes a location as input. Function calling bridges the gap between human language and the structured data needed to interact with external systems.

[source,bash]
.*1. Install Vertex AI SDK for Python*
----
pip3 install --upgrade --user --quiet google-cloud-aiplatform
----

[source,bash]
.*2. Authenticate and initialize*
----
import sys

if "google.colab" in sys.modules:
    from google.colab import auth

    auth.authenticate_user()

PROJECT_ID = "888888888"  
LOCATION = "europe-west4" 

import vertexai

vertexai.init(project=PROJECT_ID, location=LOCATION)
----

[source,bash]
.*3. Import libraries*
----
import requests
from vertexai.generative_models import (
    FunctionDeclaration,
    GenerationConfig,
    GenerativeModel,
    Part,
    Tool,
)
----

=== Chat example: Using Function Calling in a chat session to answer user's questions about the Google Store

[source,bash]
.*1. Define Function*
----
get_product_info = FunctionDeclaration(
    name="get_product_info",
    description="Get the stock amount and identifier for a given product",
    parameters={
        "type": "object",
        "properties": {
            "product_name": {"type": "string", "description": "Product name"}
        },
    },
)

get_store_location = FunctionDeclaration(
    name="get_store_location",
    description="Get the location of the closest store",
    parameters={
        "type": "object",
        "properties": {"location": {"type": "string", "description": "Location"}},
    },
)

place_order = FunctionDeclaration(
    name="place_order",
    description="Place an order",
    parameters={
        "type": "object",
        "properties": {
            "product": {"type": "string", "description": "Product name"},
            "address": {"type": "string", "description": "Shipping address"},
        },
    },
)
----

NOTE: The function parameters are specified as a Python dictionary in accordance with the OpenAPI JSON schema format.

[source,bash]
.*2. Define a tool that allows the Gemini model to select from the set of 3 functions*
----
retail_tool = Tool(
    function_declarations=[
        get_product_info,
        get_store_location,
        place_order,
    ],
)
----

[source,bash]
.*3. Initilize Model with the defined Tool above*
----
model = GenerativeModel(
    "gemini-1.5-pro-001",
    generation_config=GenerationConfig(temperature=0),
    tools=[retail_tool],
)
chat = model.start_chat()
----

NOTE: The temperature parameter controls the degree of randomness in this generation. Lower temperatures are good for functions that require deterministic parameter values, while higher temperatures are good for functions with parameters that accept more diverse or creative parameter values. A temperature of 0 is deterministic. In this case, responses for a given prompt are mostly deterministic, but a small amount of variation is still possible.


NOTE: The `retail_tool` is created in step 2.

[source,bash]
.*4. Call get production info*
----
prompt = """
Do you have the Pixel 8 Pro in stock?
"""

response = chat.send_message(prompt)
response.candidates[0].content.parts[0]
----

[source,bash]
----
function_call {
  name: "get_product_info"
  args {
    fields {
      key: "product_name"
      value {
        string_value: "Pixel 8 Pro"
      }
    }
  }
}
----

NOTE: The response from the Gemini API consists of a structured data object that contains the name and parameters of the function that Gemini selected out of the available functions.

[source,bash]
.*5. call external system simutation*
----
api_response = {"sku": "GA04834-US", "in_stock": "yes"}

response = chat.send_message(
    Part.from_function_response(
        name="get_product_info",
        response={
            "content": api_response,
        },
    ),
)
response.text
----

[source,bash]
----
'Yes, the Pixel 8 Pro is in stock. \n'
----

[source,bash]
.*6. Call get production info*
----
prompt = """
What about the Pixel 8? Is there a store in
Mountain View, CA that I can visit to try one out?
"""

response = chat.send_message(prompt)
response.candidates[0].content.parts[0]
----

[source,bash]
----
function_call {
  name: "get_product_info"
  args {
    fields {
      key: "product_name"
      value {
        string_value: "Pixel 8"
      }
    }
  }
}
----

[source,bash]
.*7. call external system simutation*
----
api_response = {"sku": "GA08475-US", "in_stock": "yes"}

response = chat.send_message(
    Part.from_function_response(
        name="get_product_info",
        response={
            "content": api_response,
        },
    ),
)
response.candidates[0].content.parts[0]
----

[source,bash]
----
function_call {
  name: "get_store_location"
  args {
    fields {
      key: "location"
      value {
        string_value: "Mountain View, CA"
      }
    }
  }
}
----

NOTE: The Gemini API respond with a second function call to `get_store_location` rather than `get_product_info`.

[source,bash]
.*8. call get_store_location*
----
api_response = {"store": "2000 N Shoreline Blvd, Mountain View, CA 94043, US"}

response = chat.send_message(
    Part.from_function_response(
        name="get_store_location",
        response={
            "content": api_response,
        },
    ),
)
response.text
----

[source,bash]
----
'Yes, the Pixel 8 is in stock. You can visit the store at 2000 N Shoreline Blvd, Mountain View, CA 94043, US to try it out. \n'
----

[source,bash]
.*9. call function*
----
prompt = """
I'd like to order a Pixel 8 Pro and have it shipped to 1155 Borregas Ave, Sunnyvale, CA 94089.
"""

response = chat.send_message(prompt)
response.candidates[0].content.parts[0]
----

[source,bash]
----
function_call {
  name: "place_order"
  args {
    fields {
      key: "address"
      value {
        string_value: "1155 Borregas Ave, Sunnyvale, CA 94089"
      }
    }
    fields {
      key: "product"
      value {
        string_value: "Pixel 8 Pro"
      }
    }
  }
}
----

[source,bash]
.*10. call external system simulation*
----
api_response = {
    "payment_status": "paid",
    "order_number": 12345,
    "est_arrival": "2 days",
}

response = chat.send_message(
    Part.from_function_response(
        name="place_order",
        response={
            "content": api_response,
        },
    ),
)
response.text
----

[source,bash]
----
'Your order has been placed and will arrive in 2 days. Your order number is 12345. \n'
----

=== Address example: Using Function Calling to geocode addresses with a maps API

[source,bash]
.*1. Define function*
----
get_location = FunctionDeclaration(
    name="get_location",
    description="Get latitude and longitude for a given location",
    parameters={
        "type": "object",
        "properties": {
            "poi": {"type": "string", "description": "Point of interest"},
            "street": {"type": "string", "description": "Street name"},
            "city": {"type": "string", "description": "City name"},
            "county": {"type": "string", "description": "County name"},
            "state": {"type": "string", "description": "State name"},
            "country": {"type": "string", "description": "Country name"},
            "postal_code": {"type": "string", "description": "Postal code"},
        },
    },
)
----

[source,bash]
.*2. Define a tool*
----
location_tool = Tool(
    function_declarations=[get_location],
)
----

[source,bash]
.*3. call function*
----
prompt = """
I want to get the coordinates for the following address:
1600 Amphitheatre Pkwy, Mountain View, CA 94043, US
"""

response = model.generate_content(
    prompt,
    generation_config=GenerationConfig(temperature=0),
    tools=[location_tool],
)
response.candidates[0].content.parts[0]
----

[source,bash]
----
function_call {
  name: "get_location"
  args {
    fields {
      key: "city"
      value {
        string_value: "Mountain View"
      }
    }
    fields {
      key: "country"
      value {
        string_value: "US"
      }
    }
    fields {
      key: "postal_code"
      value {
        string_value: "94043"
      }
    }
    fields {
      key: "state"
      value {
        string_value: "CA"
      }
    }
    fields {
      key: "street"
      value {
        string_value: "1600 Amphitheatre Pkwy"
      }
    }
  }
}
----

[source,bash]
.*4. External map api*
----
x = response.candidates[0].content.parts[0].function_call.args

url = "https://nominatim.openstreetmap.org/search?"
for i in x:
    url += f'{i}="{x[i]}"&'
url += "format=json"

headers = {"User-Agent": "none"}
x = requests.get(url, headers=headers)
content = x.json()
content
----

[source,bash]
----
[{'place_id': 299815182,
  'licence': 'Data © OpenStreetMap contributors, ODbL 1.0. http://osm.org/copyright',
  'osm_type': 'way',
  'osm_id': 23733659,
  'lat': '37.42248575',
  'lon': '-122.08558456613565',
  'class': 'building',
  'type': 'commercial',
  'place_rank': 30,
  'importance': 6.277943083843774e-05,
  'addresstype': 'building',
  'name': 'Google Building 41',
  'display_name': 'Google Building 41, 1600, Amphitheatre Parkway, Mountain View, Santa Clara County, California, 94043, United States',
  'boundingbox': ['37.4221124', '37.4228508', '-122.0859868', '-122.0851511']},
 {'place_id': 299141099,
  'licence': 'Data © OpenStreetMap contributors, ODbL 1.0. http://osm.org/copyright',
  'osm_type': 'node',
  'osm_id': 2192620021,
  'lat': '37.4217636',
  'lon': '-122.084614',
  'class': 'office',
  'type': 'it',
  'place_rank': 30,
  'importance': 6.277943083843774e-05,
  'addresstype': 'office',
  'name': 'Google Headquarters',
  'display_name': 'Google Headquarters, 1600, Amphitheatre Parkway, Mountain View, Santa Clara County, California, 94043, United States',
  'boundingbox': ['37.4217136', '37.4218136', '-122.0846640', '-122.0845640']}]
----

=== Logging example: Using Function Calling for entity extraction only

[source,bash]
.*1. Define function*
----
extract_log_data = FunctionDeclaration(
    name="extract_log_data",
    description="Extract details from error messages in raw log data",
    parameters={
        "type": "object",
        "properties": {
            "locations": {
                "type": "array",
                "description": "Errors",
                "items": {
                    "description": "Details of the error",
                    "type": "object",
                    "properties": {
                        "error_message": {
                            "type": "string",
                            "description": "Full error message",
                        },
                        "error_code": {"type": "string", "description": "Error code"},
                        "error_type": {"type": "string", "description": "Error type"},
                    },
                },
            }
        },
    },
)
----

[source,bash]
.*2. Define a tool*
----
extraction_tool = Tool(
    function_declarations=[extract_log_data],
)
----

[source,bash]
.*3. Call function*
----
prompt = """
[15:43:28] ERROR: Could not process image upload: Unsupported file format. (Error Code: 308)
[15:44:10] INFO: Search index updated successfully.
[15:45:02] ERROR: Service dependency unavailable (payment gateway). Retrying... (Error Code: 5522)
[15:45:33] ERROR: Application crashed due to out-of-memory exception. (Error Code: 9001)
"""

response = model.generate_content(
    prompt,
    generation_config=GenerationConfig(temperature=0),
    tools=[extraction_tool],
)

response.candidates[0].content.parts[0].function_call
----

[source,bash]
----
name: "extract_log_data"
args {
  fields {
    key: "locations"
    value {
      list_value {
        values {
          struct_value {
            fields {
              key: "error_code"
              value {
                string_value: "308"
              }
            }
            fields {
              key: "error_message"
              value {
                string_value: "Could not process image upload: Unsupported file format."
              }
            }
            fields {
              key: "error_type"
              value {
                string_value: "ERROR"
              }
            }
          }
        }
        values {
          struct_value {
            fields {
              key: "error_code"
              value {
                string_value: "5522"
              }
            }
            fields {
              key: "error_message"
              value {
                string_value: "Service dependency unavailable (payment gateway). Retrying..."
              }
            }
            fields {
              key: "error_type"
              value {
                string_value: "ERROR"
              }
            }
          }
        }
        values {
          struct_value {
            fields {
              key: "error_code"
              value {
                string_value: "9001"
              }
            }
            fields {
              key: "error_message"
              value {
                string_value: "Application crashed due to out-of-memory exception."
              }
            }
            fields {
              key: "error_type"
              value {
                string_value: "ERROR"
              }
            }
          }
        }
      }
    }
  }
}
----

== Gemini API in Vertex AI

[source,bash]
.*1. Install Vertex AI SDK for Python*
----
pip3 install --upgrade --user google-cloud-aiplatform
----

[source,bash]
.*2. Authenticate and initialize*
----
import sys

# Additional authentication is required for Google Colab
if "google.colab" in sys.modules:
    # Authenticate user to Google Cloud
    from google.colab import auth

    auth.authenticate_user()

# Define project information
PROJECT_ID = ""  # @param {type:"string"}
LOCATION = "us-central1"  # @param {type:"string"}

# Initialize Vertex AI
import vertexai

vertexai.init(project=PROJECT_ID, location=LOCATION)
----

[source,bash]
.*3. Import libraries*
----
from vertexai.generative_models import GenerationConfig, GenerativeModel, Image, Part
----

=== Gemini 1.0 Pro

[source,bash]
.*1. load model*
----
model = GenerativeModel("gemini-1.0-pro")
----

[source,bash]
.*2. generate text*
----
responses = model.generate_content("Why is the sky blue?", stream=True)

for response in responses:
    print(response.text, end="")
----

[source,bash]
----
The sky is blue because of a phenomenon called Rayleigh scattering. When sunlight enters the Earth's atmosphere, it is scattered in all directions by the tiny molecules of air. Blue light has a shorter wavelength than other colors of light, so it is scattered more easily. This is why we see a blue sky.

Here are some additional details about Rayleigh scattering:

* It was first explained by Lord Rayleigh in the 19th century.
* It is responsible for the blue color of the sky, the redness of sunsets, and the polarized light of the sky.
* The intensity of Rayleigh scattering is inversely proportional to the fourth power of the wavelength of light. This means that blue light is scattered much more strongly than red light.
* Rayleigh scattering is also responsible for the polarization of light from the sky. This is because the scattered light is polarized in a plane perpendicular to the direction of the incident light.

I hope this information is helpful. Please let me know if you have any other questions.
----

[source,bash]
.*3. generate text*
----
prompt = """Create a numbered list of 10 items. Each item in the list should be a trend in the generative ai and LLM 2025.

Each trend should be less than 10 words."""  

responses = model.generate_content(prompt, stream=True)

for response in responses:
    print(response.text, end="")
----

[source,bash]
----
## Top 10 Trends in Generative AI and LLMs (2025):

1. Personalization of AI assistants.
2. Generative AI for scientific discovery.
3. AI-powered video editing and creation.
4. Hyperrealistic synthetic data generation.
5. Democratization of AI development tools.
6. LLMs for personalized education.
7. AI-driven medical diagnosis and treatment.
8. Explainable and transparent AI models.
9. AI for climate change mitigation and adaptation.
10. Responsible development and use of AI.
----

[source,bash]
.*4. Model parameters*
----
generation_config = GenerationConfig(
    temperature=0.9,
    top_p=1.0,
    top_k=32,
    candidate_count=1,
    max_output_tokens=8192,
)

responses = model.generate_content(
    "Why is the sky blue?",
    generation_config=generation_config,
    stream=True,
)

for response in responses:
    print(response.text, end="")
----

[source,bash]
----
The sky is blue because of a phenomenon called Rayleigh scattering.

When sunlight enters the Earth's atmosphere, it is scattered in all directions by the air molecules. Blue light is scattered more strongly than other colors because it has a shorter wavelength. This scattered blue light is what we see as the color of the sky.

The other colors of sunlight are also scattered, but they are scattered less strongly. This is why the sky appears blue, even though sunlight is actually white.
----

[source,bash]
.*5. multi-turn chat conversations*
----
chat = model.start_chat()

prompt = """My name is Ned. You are my personal assistant. My favorite movies are Lord of the Rings and Hobbit.

Suggest another movie I might like.
"""

responses = chat.send_message(prompt, stream=True)

for response in responses:
    print(response.text, end="")
----

[source,bash]
----
Hello, Ned. It's great to meet you! I'm happy to help you find another movie you might like. Since you enjoy Lord of the Rings and the Hobbit, I can suggest a few movies based on different aspects of those films that you seem to enjoy. 

Would you prefer something with a similar:

* **Epic fantasy world and story**: Try the *Chronicles of Narnia* series, *The Golden Compass*, or *Eragon*.
* **Medieval setting with knights and battles**: Check out *Braveheart*, *Kingdom of Heaven*, or *Excalibur*.
* **Group of unlikely heroes on a quest**: Consider *The Princess Bride*, *Willow*, or *The Goonies*.
* **Dragons and other mythical creatures**: Explore *Reign of Fire*, *Dragonheart*, or *How to Train Your Dragon*. 
----

[source,bash]
.*6. follow-up prompt base on step 5 chat*
----
prompt = "Are my favorite movies based on a book series?"

responses = chat.send_message(prompt, stream=True)

for response in responses:
    print(response.text, end="")
----

[source,bash]
----
Yes, both the Lord of the Rings and the Hobbit trilogies are based on book series written by J.R.R. Tolkien. 

* **The Lord of the Rings** is a trilogy of epic high fantasy novels published between 1954 and 1955. It follows the quest of Frodo Baggins, a hobbit from the Shire, as he and his companions journey to destroy the One Ring, an artifact of immense power created by the Dark Lord Sauron.
* **The Hobbit**, published in 1937, is a shorter novel that serves as a prequel to The Lord of the Rings. It tells the story of Bilbo Baggins, a hobbit who joins a group of dwarves on a quest to reclaim their lost treasure from the dragon Smaug.

Both book series are highly acclaimed and have been translated into numerous languages. They have also inspired countless adaptations, including the popular film trilogies directed by Peter Jackson. 
----

[source,bash]
.*7. Chat history(step 5 and 6)*
----
print(chat.history)
----

[source,bash]
----
[role: "user"
parts {
  text: "My name is Ned. You are my personal assistant. My favorite movies are Lord of the Rings and Hobbit.\n\nSuggest another movie I might like.\n"
}
, role: "model"
parts {
  text: "Hello, Ned. It\'s great to meet you! I\'m happy to help you find another movie you might like. Since you enjoy Lord of the Rings and the Hobbit, I can suggest a few movies based on different aspects of those films that you seem to enjoy. \n\nWould you prefer something with a similar:\n\n* **Epic fantasy world and story**: Try the *Chronicles of Narnia* series, *The Golden Compass*, or *Eragon*.\n* **Medieval setting with knights and battles**: Check out *Braveheart*, *Kingdom of Heaven*, or *Excalibur*.\n* **Group of unlikely heroes on a quest**: Consider *The Princess Bride*, *Willow*, or *The Goonies*.\n* **Dragons and other mythical creatures**: Explore *Reign of Fire*, *Dragonheart*, or *How to Train Your Dragon*. \n"
}
, role: "user"
parts {
  text: "Are my favorite movies based on a book series?"
}
, role: "model"
parts {
  text: "Yes, both the Lord of the Rings and the Hobbit trilogies are based on book series written by J.R.R. Tolkien. \n\n* **The Lord of the Rings** is a trilogy of epic high fantasy novels published between 1954 and 1955. It follows the quest of Frodo Baggins, a hobbit from the Shire, as he and his companions journey to destroy the One Ring, an artifact of immense power created by the Dark Lord Sauron.\n* **The Hobbit**, published in 1937, is a shorter novel that serves as a prequel to The Lord of the Rings. It tells the story of Bilbo Baggins, a hobbit who joins a group of dwarves on a quest to reclaim their lost treasure from the dragon Smaug.\n\nBoth book series are highly acclaimed and have been translated into numerous languages. They have also inspired countless adaptations, including the popular film trilogies directed by Peter Jackson. "
}
]
----

=== Gemini 1.0 Pro Vision

[source,bash]
.*1. load model*
----
multimodal_model = GenerativeModel("gemini-1.0-pro-vision")
----

[source,bash]
.*2. define helper functions*
----
import http.client
import typing
import urllib.request

import IPython.display
from PIL import Image as PIL_Image
from PIL import ImageOps as PIL_ImageOps


def display_images(
    images: typing.Iterable[Image],
    max_width: int = 600,
    max_height: int = 350,
) -> None:
    for image in images:
        pil_image = typing.cast(PIL_Image.Image, image._pil_image)
        if pil_image.mode != "RGB":
            # RGB is supported by all Jupyter environments (e.g. RGBA is not yet)
            pil_image = pil_image.convert("RGB")
        image_width, image_height = pil_image.size
        if max_width < image_width or max_height < image_height:
            # Resize to display a smaller notebook image
            pil_image = PIL_ImageOps.contain(pil_image, (max_width, max_height))
        IPython.display.display(pil_image)


def get_image_bytes_from_url(image_url: str) -> bytes:
    with urllib.request.urlopen(image_url) as response:
        response = typing.cast(http.client.HTTPResponse, response)
        image_bytes = response.read()
    return image_bytes


def load_image_from_url(image_url: str) -> Image:
    image_bytes = get_image_bytes_from_url(image_url)
    return Image.from_bytes(image_bytes)


def get_url_from_gcs(gcs_uri: str) -> str:
    # converts gcs uri to url for image display.
    url = "https://storage.googleapis.com/" + gcs_uri.replace("gs://", "").replace(
        " ", "%20"
    )
    return url


def print_multimodal_prompt(contents: list):
    """
    Given contents that would be sent to Gemini,
    output the full multimodal prompt for ease of readability.
    """
    for content in contents:
        if isinstance(content, Image):
            display_images([content])
        elif isinstance(content, Part):
            url = get_url_from_gcs(content.file_data.file_uri)
            IPython.display.display(load_image_from_url(url))
        else:
            print(content)
----

[source,bash]
.*3. Generate text from local image and text*
----
# Download an image from Google Cloud Storage
! gsutil cp "gs://cloud-samples-data/generative-ai/image/320px-Felis_catus-cat_on_snow.jpg" ./image.jpg

# Load from local file
image = Image.load_from_file("image.jpg")

# Prepare contents
prompt = "Describe this image?"
contents = [image, prompt]

responses = multimodal_model.generate_content(contents, stream=True)

print("-------Prompt--------")
print_multimodal_prompt(contents)

print("\n-------Response--------")
for response in responses:
    print(response.text, end="")
----

[source,bash]
----
-------Prompt--------
<image>
Describe this image?

-------Response--------
 This is a photo of a cat walking in the snow. The cat is brown and white, and it has a long tail. The snow is white and it is covering the ground. The cat is looking at the camera.
----

[source,bash]
.*4. Generate text from text & image(s)*
----
# Load image from Cloud Storage URI
gcs_uri = "gs://cloud-samples-data/generative-ai/image/boats.jpeg"

# Prepare contents
image = Part.from_uri(gcs_uri, mime_type="image/jpeg")
prompt = "Describe the scene?"
contents = [image, prompt]

responses = multimodal_model.generate_content(contents, stream=True)

print("-------Prompt--------")
print_multimodal_prompt(contents)

print("\n-------Response--------")
for response in responses:
    print(response.text, end="")
----

[source,bash]
----

-------Prompt--------
<image>
Describe the scene?

-------Response--------
 Two pontoon boats are anchored in the Charles River in Boston, Massachusetts. In the background are two bridges and the Boston skyline.
----

[source,bash]
.*5. Images with direct links*
----
# Load image from Cloud Storage URI
image_url = (
    "https://storage.googleapis.com/cloud-samples-data/generative-ai/image/boats.jpeg"
)
image = load_image_from_url(image_url)  # convert to bytes

# Prepare contents
prompt = "Describe the scene?"
contents = [image, prompt]

responses = multimodal_model.generate_content(contents, stream=True)

print("-------Prompt--------")
print_multimodal_prompt(contents)

print("\n-------Response--------")
for response in responses:
    print(response.text, end="")
----

[source,bash]
----
-------Prompt--------
<image>
Describe the scene?

-------Response--------
 Two pontoon boats are anchored in the Charles River in Boston, Massachusetts. In the background are two bridges and the Boston skyline.
----

[source,bash]
.*6. Combining multiple images and text prompts for few-shot prompting*
----
# Load images from Cloud Storage URI
image1_url = "https://storage.googleapis.com/github-repo/img/gemini/intro/landmark1.jpg"
image2_url = "https://storage.googleapis.com/github-repo/img/gemini/intro/landmark2.jpg"
image3_url = "https://storage.googleapis.com/github-repo/img/gemini/intro/landmark3.jpg"
image1 = load_image_from_url(image1_url)
image2 = load_image_from_url(image2_url)
image3 = load_image_from_url(image3_url)

# Prepare prompts
prompt1 = """{"city": "London", "Landmark:", "Big Ben"}"""
prompt2 = """{"city": "Paris", "Landmark:", "Eiffel Tower"}"""

# Prepare contents
contents = [image1, prompt1, image2, prompt2, image3]

responses = multimodal_model.generate_content(contents, stream=True)

print("-------Prompt--------")
print_multimodal_prompt(contents)

print("\n-------Response--------")
for response in responses:
    print(response.text, end="")
----

[source,bash]
----
{"city": "London", "Landmark:", "Big Ben"}
{"city": "Paris", "Landmark:", "Eiffel Tower"}
{"city": "Rome", "Landmark:", "Colosseum"}
----

[source,bash]
.*7. Generate text from a video file*
----
file_path = "github-repo/img/gemini/multimodality_usecases_overview/pixel8.mp4"
video_uri = f"gs://{file_path}"
video_url = f"https://storage.googleapis.com/{file_path}"

IPython.display.Video(video_url, width=450)

prompt = """
Answer the following questions using the video only:
What is the profession of the main person?
What are the main features of the phone highlighted?
Which city was this recorded in?
Provide the answer JSON.
"""

video = Part.from_uri(video_uri, mime_type="video/mp4")
contents = [prompt, video]

responses = multimodal_model.generate_content(contents, stream=True)

for response in responses:
    print(response.text, end="")
----

[source,json]
----
{
  "person": {
    "name": "Saeka Shimada",
    "profession": "photographer"
  },
  "phone": {
    "brand": "Google",
    "model": "Pixel 8"
  },
  "city": "Tokyo",
  "features": [
    "Video Boost",
    "Night Sight"
  ]
}
----

== Streamlit Framework + Cloud Run + Vertex AI Gemini API

[source, bash]
.*1. get code*
----
git clone https://github.com/GoogleCloudPlatform/generative-ai.git --depth=1
cd generative-ai/gemini/sample-apps/gemini-streamlit-cloudrun
----

[source, bash]
.*2. Setup the Python virtual environment and install the dependencies*
----
python3 -m venv gemini-streamlit
source gemini-streamlit/bin/activate
pip install -r requirements.txt
----

[source, bash]
.*3. setup environment and run locally*
----
GCP_PROJECT='88888888'
GCP_REGION='europe-west1'

streamlit run app.py \
  --browser.serverAddress=localhost \
  --server.enableCORS=false \
  --server.enableXsrfProtection=false \
  --server.port 8080
----

[source, bash]
.*3. build and deploy app to cloud run*
----
AR_REPO='gemini-repo'
SERVICE_NAME='gemini-streamlit-app' 

gcloud artifacts repositories create "$AR_REPO" --location="$GCP_REGION" --repository-format=Docker

gcloud builds submit --tag "$GCP_REGION-docker.pkg.dev/$GCP_PROJECT/$AR_REPO/$SERVICE_NAME"

gcloud run deploy "$SERVICE_NAME" \
  --port=8080 \
  --image="$GCP_REGION-docker.pkg.dev/$GCP_PROJECT/$AR_REPO/$SERVICE_NAME" \
  --allow-unauthenticated \
  --region=$GCP_REGION \
  --platform=managed  \
  --project=$GCP_PROJECT \
  --set-env-vars=GCP_PROJECT=$GCP_PROJECT,GCP_REGION=$GCP_REGION
----

[source, bash]
----
...
Done.                                                                          
Service [gemini-streamlit-app] revision [gemini-streamlit-app-00001-wlh] has been deployed and is serving 100 percent of traffic.
Service URL: https://gemini-streamlit-app-392929949059.europe-west1.run.app
----

