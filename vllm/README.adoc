= VLLM
:toc: manual

== vllm serve

[source, bash]
.*1. Download Model Image*
----
huggingface-cli download Qwen/Qwen3-8B --local-dir ./
----

[source, bash]
.*2. Setup Python*
----
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O miniconda.sh
/home/kylin/miniconda/bin/conda init bash
conda tos accept --override-channels --channel https://repo.anaconda.com/pkgs/main
conda tos accept --override-channels --channel https://repo.anaconda.com/pkgs/r
conda create -n vllm python=3.12 -y
conda activate vllm
pip install vllm
----

[source, bash]
.*3. vllm serve*
----
vllm serve /home/kylin/Qwen3-8B
----
